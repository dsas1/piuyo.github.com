WEBVTT
Kind: captions
Language: en

00:00:01.160 --> 00:00:05.520
In addition to supervised and unsupervised learning,

00:00:05.520 --> 00:00:10.665
there are a handful of other data science methods that make up the Data Science Toolbox.

00:00:10.665 --> 00:00:14.700
For example, a class of learning methods that falls between

00:00:14.700 --> 00:00:20.130
supervised and unsupervised methods is known as semi-supervised learning.

00:00:20.130 --> 00:00:23.250
Semi-supervised learning generally needs

00:00:23.250 --> 00:00:28.275
only a small subset of cases for which an outcome measure is available.

00:00:28.275 --> 00:00:34.405
This can overcome the sometimes very costly need to classify outcomes in your data.

00:00:34.405 --> 00:00:38.570
We often refer to cases with outcomes as labeled,

00:00:38.570 --> 00:00:43.385
whereas cases with no outcome are unlabeled.

00:00:43.385 --> 00:00:50.959
For example, a medical unit may want to diagnose lung problems from CT or MRI scans.

00:00:50.959 --> 00:00:54.680
Having a radiologist classify the tens of thousands of

00:00:54.680 --> 00:00:59.645
cases often required for supervised learning is often too expensive.

00:00:59.645 --> 00:01:06.080
Semi-supervised methods require only a small subset of labeled cases and can learn

00:01:06.080 --> 00:01:09.545
the most likely classifications for the large number of

00:01:09.545 --> 00:01:16.200
unlabeled cases using a combination of supervised and unsupervised techniques.

00:01:16.510 --> 00:01:20.615
Two remaining families of data science methods

00:01:20.615 --> 00:01:24.889
include reinforcement learning and recommender systems.

00:01:24.889 --> 00:01:28.115
Reinforcement learning represents a family of

00:01:28.115 --> 00:01:32.375
algorithms that learn in a trial and error fashion.

00:01:32.375 --> 00:01:36.965
They interact with an environment towards a specific objective,

00:01:36.965 --> 00:01:43.370
modifying actions in repeated iterations after receiving some feedback or reward.

00:01:43.370 --> 00:01:48.380
The game-playing agents that have prominently beat chess grand-masters

00:01:48.380 --> 00:01:53.585
and world champions and Go are based on reinforcement learning techniques.

00:01:53.585 --> 00:01:58.190
Reinforcement learning also plays a role in self-driving cars,

00:01:58.190 --> 00:02:01.310
optimizing factory floor conditions,

00:02:01.310 --> 00:02:05.140
and teaching robots how to complete tasks.

00:02:05.140 --> 00:02:10.970
Finally, recommender systems exploit similarities between cases,

00:02:10.970 --> 00:02:16.010
such as customer purchase behavior to recommend a next item or

00:02:16.010 --> 00:02:21.605
action based on what was preferred by those most similar to the case in hand.

00:02:21.605 --> 00:02:26.060
Examples of recommender systems include product recommendation,

00:02:26.060 --> 00:02:28.370
such as what you might find on Amazon or

00:02:28.370 --> 00:02:34.579
other retailer websites and Next Best Offer programs that are common in banking,

00:02:34.579 --> 00:02:37.670
insurance, and many other contexts.

00:02:37.670 --> 00:02:41.210
Content recommendation like you might see on

00:02:41.210 --> 00:02:44.675
Facebook or Twitter is based in recommender systems,

00:02:44.675 --> 00:02:49.505
as our playlist recommendations from Netflix, YouTube or Spotify,

00:02:49.505 --> 00:02:53.180
and even restaurant or online dating recommendations

00:02:53.180 --> 00:02:56.390
found in sites specific to those interests.

00:02:56.390 --> 00:02:58.985
Now that we have built up our foundation a little more,

00:02:58.985 --> 00:03:02.700
it's time to test again. Good luck.

